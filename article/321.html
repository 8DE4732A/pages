
        <html lang="en">
            <head>
                <meta charset="utf-8">
                <title>巨大隐患：亚马逊新语音技术或被不法分子伪造声音</title>
            </head>
            <body>
                <div>
<div><a href="/images/144.gif" target="_blank"><img src="/images/144.gif" title="警告!"/></a></div>
<p>北京时间6月24日消息，当地时间周三，亚马逊AI语音数字助理Alexa可模仿任何声音的人性化演示文稿在网络上引起轰动，<strong>人们对于是否可能出现伪造声音的情况表示担忧，例如使用合法录音来模仿人们说他们实际上没有说过的话，来实施绑架诈骗或在公司重大决策中伪造音频。</strong></p> </div>
                <div>
<p>当地周三，亚马逊高级副总裁罗希特·普拉萨德(Rohit Prasad)透露其公司正在开发一种系统，可使AI语音数字助理Alexa在听不到一分钟音频后模仿任何声音。</p><p><a href="/images/1099.jpg" target="_blank"><img src="/images/1099.jpg"/></a></p><p>该技术研发的消息公布时，人们只是简单地想到其带来的好处，Alexa的首席科学家Rohit Prasad也在周三的公司演示中充分展示了数字助理的人性化，<strong>演示了Alexa冒充一位祖母阅读《绿野仙踪》摘录的画面。</strong>他表示，同理心和情感等人类特征是与人建立信任的关键，“在疫情持续的这段时间里，当我们失去了我们所爱的人时，这些属性变得更加重要”，<strong>“虽然人工智能无法消除那种失落的痛苦，但绝对可以让他们的记忆永存。”</strong>该演示给人以将该技术作为一种数字化死者复活工具的印象。</p><p><strong>但普拉萨德在随后拉斯维加斯举行的亚马逊技术会议中表示，</strong><strong>该服务的主要目的不是模拟死者的声音。</strong></p><p>随着该演示在网络上发酵讨论，引发了巨大轰动，与此同时出现了一些表示担忧的声音——是否会使用合法的录音来模仿人们说他们实际上没有发声的话。布法罗大学计算机科学与工程教授Siwei Lyu的研究涉及深度伪造和数字媒体取证，他表示他对这一发展感到担忧，“亚马逊开发的语音转换技术肯定有好处，但我们应该意识到潜在的误用，<strong>例如绑匪可以在电话中伪装成家人或朋友来引诱不知情的受害者，或者高层管理人员在对公司财务状况发表言论时伪造录音，可能会使股市出现问题。”</strong></p><p>虽然亚马逊没有透露Alexa的新功能何时推出，但类似的技术可能会让这种恶作剧变得容易得多。普拉萨德说，亚马逊已经学会根据不到一分钟人的讲话来模拟声音，而以前需要在工作室里才能完成这些工作。</p><p><br/></p> </div>
            </body>
        </html>
        