
        <html lang="en">
            <head>
                <meta charset="utf-8">
                <title>新出生的机器狗，打滚1小时后自己掌握走路，吴恩达开山大弟子最新成果</title>
            </head>
            <body>
                <div>
<div><a href="/images/361.png" target="_blank"><img src="/images/361.png" title="AI 人工智能"/></a></div>
<p>现在，让机械狗自己打滚一个小时，它就能学会走路了！步态看着相当有模有样，还能扛住大棍子的一通狂怼，就算是摔了个四仰八叉，翻个身自己又站起来了。</p> </div>
                <div>
<p><img src="/images/7146.gif"/></p><p>文/明敏</p><p><img src="/images/7147.gif"/></p><p><img src="/images/7148.gif"/></p><p><img src="/images/7149.gif"/></p><p>如此看来，训机械狗和普通训狗真是要没什么两样了啊。</p><p>这就是UC伯克利大学带来的最新成果，让机器人直接在实际环境中训练学习，不再依赖于模拟器。</p><p>应用这一方法，研究人员在短时间内训练出了4个机器人。</p><p><img src="/images/7150.gif"/></p><p>比如开头看到的1小时学会走路的机械狗；</p><p>还有2个机械臂，在8-10小时实战抓取后，表现接近于人类水平；</p><p><img src="/images/7151.gif"/></p><p>以及一个拥有计算机视觉的小机器人，在自己摸索2小时后，能丝滑地滚动到指定位置。</p><p><img src="/images/7152.gif"/></p><p>该研究由Pieter Abbeel等人提出，Pieter Abbeel是吴恩达的第一位博士生，前不久他刚刚获得2021 ACM 计算奖（ACM Prize in Computing）。</p><p>目前，该方法的所有软件基础架构已经开源。</p><p><strong>一个叫做“空想家”的算法</strong></p><p>本文方法的pipeline大致可分为4步：</p><p><img src="/images/7153.png"/></p><p>第一步，是先把机器人放在真实环境里，收集数据。</p><p>第二步，把这些数据传输到Replay Buffer。这一步骤就是利用历史数据进行训练、“总结经验”，高效利用收集到的样本。</p><p>第三步，World Model会对已有经验进行学习，然后“脑补”出策略。</p><p>第四步，再用演员评论家（Actor Critic）算法来提升策略梯度法的性能。</p><p>然后循环往复，将已经提炼出的办法再使用到机器人身上，最后达到一种“自己摸索学习”的感觉。</p><p>具体来看，这里的核心环节是World Model。</p><p>World Models是2018年由DAVID HA等人提出的一种快速无监督学习方式，获得了NIPS 2018的Oral Presentation。</p><p>它的核心理念是认为人类是基于已有经验，形成了一个心理世界模型，我们所做的决定和行动都是基于这个内部模型。</p><p>比如人类在打棒球时，做出反应的速度远比视觉信息传达到大脑中的快，那么在这种情况下还能正确回球的原因，就是因为大脑已经做出了本能的预测。</p><p><img src="/images/7154.png"/></p><p>此前，基于World Model这种“脑补”的学习方法，Google提出了Dreamer这种可扩展的强化学习方法。</p><p>这一次提出的方法是在此基础上，叫做DayDreamer。</p><p>（貌似可以叫做空想家？</p><p><img src="/images/7155.png"/></p><p>具体来看，World Model就是一个智能体模型。</p><p>它包括一个视觉感知组件，能将看到的图像压缩成一个低维的表征向量作为模型输入。</p><p>同时还有一个记忆组件，可以基于历史信息，对未来的表征向量做出预测。</p><p>最后，还包括一个决策组件，它能基于视觉感知组件、决策组件的表征向量，决定采取怎样的动作。</p><p><img src="/images/7156.png"/></p><p>现在，我们回到本次UC伯克利学者提出的方法。</p><p>不难发现，其中World Model Learning部分的逻辑就是一个经验积累的过程，Behavior Learning部分则是一个动作输出的过程。</p><p><img src="/images/7157.png"/></p><p>本篇论文方法的提出，主要解决了机器人训练中两方面的问题：</p><p>效率和准确率。</p><p>一般来说，训练机器人的常规方法是强化学习，通过反复实验来调整机器人的运作。</p><p>不过这种方法往往需要非常大量的测试，才能达到很好的效果。</p><p>不仅效率低下，而且训练需要付出的成本也不低。</p><p>后来，不少人提出在模拟器中对机器人进行训练，可以很好增效降本。</p><p>但是本文作者认为，模拟器训练方法在准确性方面的表现还是不够好，只有真实的环境才能让机器人达到最好的效果。</p><p>从结果来看，在训练机器狗的过程中，只花10分钟时间，机器狗就能适应自己的行为了。</p><p>和SAC方法对比来看，效果有明显提升。</p><p><img src="/images/7158.png"/></p><p>在机械臂训练过程中，这一新方法还克服了视觉定位和稀疏奖励的挑战，几小时内的训练成果明显优于其他方法。</p><p><img src="/images/7159.png"/></p><p><strong>研究团队</strong></p><p>值得一提的是，本次带来新成果的研究团队成员，也非常令人瞩目。</p><p>其中，Pieter Abbeel是吴恩达的开山大弟子。</p><p><img src="/images/7160.jpg"/></p><p>他现在是UC伯克利电气工程和计算机科学教授，伯克利机器人学习实验室主任，伯克利AI研究院共同主任，曾加入过OpenAI。</p><p>前不久，他还获得了2021 ACM 计算奖（ACM Prize in Computing），以表彰其在机器人学习方面的贡献。</p><p>与此同时，他还是AI机器人公司Covariant的联合创始人。</p><p><img src="/images/7161.jpg"/></p><p>另一位Ken Goldberg，也是AI领域的顶级专家。</p><p><img src="/images/7162.jpg"/></p><p>他现在是UC伯克利工程教授，研究方向为强化学习、人机交互等。</p><p>2005年，他被评选为IEEE院士。</p><p>与此同时，Goldberg还是一位艺术家，是UC伯克利艺术、科技文化研讨会的奠基人。</p><p>此外，Philipp Wu、Alejandro Escontrela、Danijar Hafner三人为共同一作。</p><p>其中Philipp Wu还只是UC伯克利一位大四的学生。</p><p><strong>One More Thing</strong></p><p>在观看机械狗训练的视频时，我们发现研究人员使用的Unitree机械狗，</p><p><img src="/images/7163.png"/></p><p>这个品牌来自中国企业宇树科技，之前登上过春晚的机器小牛，也来自它家。</p><p><img src="/images/7164.gif"/></p><p>而且，最近宇树机器狗集体进行Go1测试的视频曝光，还在国外火了一波。</p><p><img src="/images/7165.gif"/></p><p>论文地址：</p><p>https：//danijar.com/project/daydreamer/</p><p>参考链接：https：//worldmodels.github.io/</p> </div>
            </body>
        </html>
        